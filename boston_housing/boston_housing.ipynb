{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习工程师纳米学位\n",
    "## 模型评价与验证\n",
    "## 项目 1: 预测波士顿房价\n",
    "\n",
    "\n",
    "欢迎来到机器学习工程师纳米学位的第一个项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能来让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以**编程练习**开始的标题表示接下来的内容中有需要你必须实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以**TODO**标出。请仔细阅读所有的提示！\n",
    "\n",
    "除了实现代码外，你还**必须**回答一些与项目和实现有关的问题。每一个需要你回答的问题都会以**'问题 X'**为标题。请仔细阅读每个问题，并且在问题后的**'回答'**文字框中写出完整的答案。你的项目将会根据你对问题的回答和撰写代码所实现的功能来进行评分。\n",
    "\n",
    ">**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第一步. 导入数据\n",
    "在这个项目中，你将利用马萨诸塞州波士顿郊区的房屋信息数据训练和测试一个模型，并对模型的性能和预测能力进行测试。通过该数据训练后的好的模型可以被用来对房屋做特定预测---尤其是对房屋的价值。对于房地产经纪等人的日常工作来说，这样的预测模型被证明非常有价值。\n",
    "\n",
    "此项目的数据集来自[UCI机器学习知识库(数据集已下线)](https://archive.ics.uci.edu/ml/datasets.html)。波士顿房屋这些数据于1978年开始统计，共506个数据点，涵盖了麻省波士顿不同郊区房屋14种特征的信息。本项目对原始数据集做了以下处理：\n",
    "- 有16个`'MEDV'` 值为50.0的数据点被移除。 这很可能是由于这些数据点包含**遗失**或**看不到的值**。\n",
    "- 有1个数据点的 `'RM'` 值为8.78. 这是一个异常值，已经被移除。\n",
    "- 对于本项目，房屋的`'RM'`， `'LSTAT'`，`'PTRATIO'`以及`'MEDV'`特征是必要的，其余不相关特征已经被移除。\n",
    "- `'MEDV'`特征的值已经过必要的数学转换，可以反映35年来市场的通货膨胀效应。\n",
    "\n",
    "运行下面区域的代码以载入波士顿房屋数据集，以及一些此项目所需的Python库。如果成功返回数据集的大小，表示数据集已载入成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 载入此项目所需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import visuals as vs # Supplementary code\n",
    "\n",
    "# 检查你的Python版本\n",
    "from sys import version_info\n",
    "if version_info.major != 2 and version_info.minor != 7:\n",
    "    raise Exception('请使用Python 2.7来完成此项目')\n",
    "    \n",
    "# 让结果在notebook中显示\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset has 489 data points with 4 variables each.\n"
     ]
    }
   ],
   "source": [
    "# 载入波士顿房屋的数据集\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "    \n",
    "# 完成\n",
    "print \"Boston housing dataset has {} data points with {} variables each.\".format(*data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第二步. 分析数据\n",
    "在项目的第一个部分，你会对波士顿房地产数据进行初步的观察并给出你的分析。通过对数据的探索来熟悉数据可以让你更好地理解和解释你的结果。\n",
    "\n",
    "由于这个项目的最终目标是建立一个预测房屋价值的模型，我们需要将数据集分为**特征(features)**和**目标变量(target variable)**。\n",
    "- **特征** `'RM'`， `'LSTAT'`，和 `'PTRATIO'`，给我们提供了每个数据点的数量相关的信息。\n",
    "- **目标变量**：` 'MEDV'`，是我们希望预测的变量。\n",
    "\n",
    "他们分别被存在`features`和`prices`两个变量名中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习 1：基础统计运算\n",
    "你的第一个编程练习是计算有关波士顿房价的描述统计数据。我们已为你导入了` numpy `，你需要使用这个库来执行必要的计算。这些统计数据对于分析模型的预测结果非常重要的。\n",
    "在下面的代码中，你要做的是：\n",
    "- 计算`prices`中的`'MEDV'`的最小值、最大值、均值、中值和标准差；\n",
    "- 将运算结果储存在相应的变量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Boston housing dataset:\n",
      "\n",
      "Minimum price: $105,000.00\n",
      "Maximum price: $1,024,800.00\n",
      "Mean price: $454,342.94\n",
      "Median price $438,900.00\n",
      "Standard deviation of prices: $165,171.13\n"
     ]
    }
   ],
   "source": [
    "#目标：计算价值的最小值\n",
    "minimum_price = np.min(prices)\n",
    "\n",
    "#目标：计算价值的最大值\n",
    "maximum_price = np.max(prices)\n",
    "\n",
    "#目标：计算价值的平均值\n",
    "mean_price = np.mean(prices)\n",
    "\n",
    "#目标：计算价值的中值\n",
    "median_price = np.median(prices)\n",
    "\n",
    "#目标：计算价值的标准差\n",
    "std_price = np.std(prices)\n",
    "\n",
    "#目标：输出计算的结果\n",
    "print \"Statistics for Boston housing dataset:\\n\"\n",
    "print \"Minimum price: ${:,.2f}\".format(minimum_price)\n",
    "print \"Maximum price: ${:,.2f}\".format(maximum_price)\n",
    "print \"Mean price: ${:,.2f}\".format(mean_price)\n",
    "print \"Median price ${:,.2f}\".format(median_price)\n",
    "print \"Standard deviation of prices: ${:,.2f}\".format(std_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 1 - 特征观察\n",
    "\n",
    "如前文所述，本项目中我们关注的是其中三个值:`'RM'`、`'LSTAT'` 和`'PTRATIO'`，对每一个数据点:\n",
    "- `'RM'` 是该地区中每个房屋的平均房间数量；\n",
    "- `'LSTAT'` 是指该地区有多少百分比的房东属于是低收入阶层（有工作但收入微薄）；\n",
    "- `'PTRATIO'` 是该地区的中学和小学里，学生和老师的数目比（`学生/老师`）。\n",
    "\n",
    "_凭直觉，上述三个特征中对每一个来说，你认为增大该特征的数值，`'MEDV'`的值会是**增大**还是**减小**呢？每一个答案都需要你给出理由。_\n",
    "\n",
    "**提示：**你预期一个`'RM'` 值是6的房屋跟`'RM'` 值是7的房屋相比，价值更高还是更低呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 1 - 回答：\n",
    "RM值增大，MEDV的值也会增大，拥有房间数量更多的房屋的价值越高。\n",
    "\n",
    "LSTAT值增大，MEDV的值会减小，低收入阶层比例更高的地区，房屋价值越低。\n",
    "\n",
    "PTRATIO值增大，MEDV的值会减小。PTRATIO值更大，说明学生更多，老师更少，也就是说教育资源更加欠缺，所以房屋的价值更小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习 2: 数据分割与重排\n",
    "接下来，你需要把波士顿房屋数据集分成训练和测试两个子集。通常在这个过程中，数据也会被重排列，以消除数据集中由于顺序而产生的偏差。\n",
    "在下面的代码中，你需要\n",
    "\n",
    "使用 `sklearn.model_selection` 中的 `train_test_split`， 将`features`和`prices`的数据都分成用于训练的数据子集和用于测试的数据子集。\n",
    "  - 分割比例为：80%的数据用于训练，20%用于测试；\n",
    "  - 选定一个数值以设定 `train_test_split` 中的 `random_state` ，这会确保结果的一致性；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[        RM  LSTAT  PTRATIO\n",
       " 64   7.104   8.05     18.6\n",
       " 240  6.433   9.52     19.1\n",
       " 14   6.096  10.26     21.0\n",
       " 105  5.851  16.47     20.9\n",
       " 199  6.326  10.97     18.6\n",
       " 402  6.824  22.74     20.2\n",
       " 348  6.112  12.67     20.2\n",
       " 160  6.250   5.50     14.7\n",
       " 345  6.212  17.60     20.2\n",
       " 364  6.545  21.08     20.2\n",
       " 73   6.245   7.54     19.2\n",
       " 6    6.012  12.43     15.2\n",
       " 219  7.163   6.36     17.4\n",
       " 277  6.315   7.60     16.6\n",
       " 443  6.701  16.42     20.2\n",
       " 398  6.434  29.05     20.2\n",
       " 286  5.790  15.84     16.0\n",
       " 304  5.705  11.50     18.4\n",
       " 237  5.605  18.46     19.1\n",
       " 202  5.344  23.09     18.6\n",
       " 410  6.202  14.52     20.2\n",
       " 230  6.481   6.36     16.6\n",
       " 95   6.625   6.65     18.0\n",
       " 423  5.818  22.11     20.2\n",
       " 482  5.569  15.10     19.2\n",
       " 311  6.041   7.70     19.6\n",
       " 347  6.127  11.48     20.2\n",
       " 309  6.426   7.20     19.6\n",
       " 467  5.871  13.34     20.2\n",
       " 229  7.358   4.73     17.4\n",
       " ..     ...    ...      ...\n",
       " 159  6.510   7.39     14.7\n",
       " 3    6.998   2.94     18.7\n",
       " 321  6.031   7.83     16.9\n",
       " 294  6.616   8.93     18.4\n",
       " 7    6.172  19.15     15.2\n",
       " 224  8.337   2.47     17.4\n",
       " 458  6.162  24.10     20.2\n",
       " 395  4.628  34.37     20.2\n",
       " 13   5.949   8.26     21.0\n",
       " 218  8.040   3.13     17.4\n",
       " 96   6.163  11.34     18.0\n",
       " 239  6.226  10.15     19.1\n",
       " 40   7.024   1.98     18.3\n",
       " 20   5.570  21.02     21.0\n",
       " 123  5.856  25.41     19.1\n",
       " 164  6.319  11.10     14.7\n",
       " 313  6.415   6.12     19.6\n",
       " 291  6.495   8.67     16.1\n",
       " 459  6.484  18.68     20.2\n",
       " 172  6.020  10.11     16.6\n",
       " 383  5.987  26.77     20.2\n",
       " 210  6.642   9.69     16.4\n",
       " 190  7.287   4.08     12.6\n",
       " 234  6.358  11.22     16.6\n",
       " 158  6.066   6.43     14.7\n",
       " 26   5.813  14.81     21.0\n",
       " 198  5.891  10.87     18.6\n",
       " 196  7.610   3.11     14.7\n",
       " 16   5.935   6.58     21.0\n",
       " 471  5.454  18.06     20.1\n",
       " \n",
       " [391 rows x 3 columns],         RM  LSTAT  PTRATIO\n",
       " 161  5.854  11.64     14.7\n",
       " 30   5.713  22.60     21.0\n",
       " 374  6.051  18.76     20.2\n",
       " 473  5.093  29.68     20.1\n",
       " 405  5.648  14.10     20.2\n",
       " 125  5.986  14.81     19.1\n",
       " 451  5.926  18.13     20.2\n",
       " 427  5.854  23.79     20.2\n",
       " 139  6.151  18.46     21.2\n",
       " 484  6.593   9.67     21.0\n",
       " 474  5.983  18.07     20.1\n",
       " 226  6.726   8.05     17.4\n",
       " 37   5.850   8.77     19.2\n",
       " 401  5.957  20.62     20.2\n",
       " 61   5.966  14.44     19.7\n",
       " 70   6.417   6.72     19.2\n",
       " 4    7.147   5.33     18.7\n",
       " 251  7.203   9.59     13.0\n",
       " 208  6.182   9.47     18.6\n",
       " 166  5.875  14.43     14.7\n",
       " 300  6.122   5.98     18.4\n",
       " 91   6.405   8.20     17.8\n",
       " 221  6.552   3.76     17.4\n",
       " 222  5.981  11.65     17.4\n",
       " 115  5.928  15.76     17.8\n",
       " 249  7.333   7.79     13.0\n",
       " 5    6.430   5.21     18.7\n",
       " 21   5.965  13.83     21.0\n",
       " 424  6.406  19.52     20.2\n",
       " 485  6.120   9.08     21.0\n",
       " ..     ...    ...      ...\n",
       " 245  8.259   3.54     19.1\n",
       " 394  6.657  21.22     20.2\n",
       " 121  6.004  14.27     19.1\n",
       " 429  6.341  17.79     20.2\n",
       " 355  3.863  13.33     20.2\n",
       " 211  5.951  17.92     16.4\n",
       " 89   7.079   5.70     17.8\n",
       " 238  6.108   9.16     19.1\n",
       " 207  5.412  29.55     18.6\n",
       " 162  6.101   9.81     14.7\n",
       " 213  6.951   9.71     17.4\n",
       " 248  7.454   3.11     15.9\n",
       " 464  6.750   7.74     20.2\n",
       " 124  5.879  17.58     19.1\n",
       " 132  6.372  11.12     21.2\n",
       " 366  5.520  24.56     20.2\n",
       " 19   5.727  11.28     21.0\n",
       " 206  6.375   9.38     18.6\n",
       " 444  6.376  14.65     20.2\n",
       " 341  5.884   7.79     18.3\n",
       " 463  6.242  10.74     20.2\n",
       " 126  5.613  27.26     19.1\n",
       " 113  6.092  17.09     17.8\n",
       " 399  6.782  25.79     20.2\n",
       " 59   5.927   9.22     19.7\n",
       " 357  4.138  37.97     20.2\n",
       " 152  5.012  12.12     14.7\n",
       " 92   6.442   8.16     18.2\n",
       " 212  6.373  10.50     16.4\n",
       " 371  4.880  30.62     20.2\n",
       " \n",
       " [98 rows x 3 columns], 64     693000.0\n",
       " 240    514500.0\n",
       " 14     382200.0\n",
       " 105    409500.0\n",
       " 199    512400.0\n",
       " 402    176400.0\n",
       " 348    474600.0\n",
       " 160    567000.0\n",
       " 345    373800.0\n",
       " 364    228900.0\n",
       " 73     491400.0\n",
       " 6      480900.0\n",
       " 219    663600.0\n",
       " 277    468300.0\n",
       " 443    344400.0\n",
       " 398    151200.0\n",
       " 286    426300.0\n",
       " 304    340200.0\n",
       " 237    388500.0\n",
       " 202    420000.0\n",
       " 410    228900.0\n",
       " 230    497700.0\n",
       " 95     596400.0\n",
       " 423    220500.0\n",
       " 482    367500.0\n",
       " 311    428400.0\n",
       " 347    476700.0\n",
       " 309    499800.0\n",
       " 467    432600.0\n",
       " 229    661500.0\n",
       "          ...   \n",
       " 159    489300.0\n",
       " 3      701400.0\n",
       " 321    407400.0\n",
       " 294    596400.0\n",
       " 7      569100.0\n",
       " 224    875700.0\n",
       " 458    279300.0\n",
       " 395    375900.0\n",
       " 13     428400.0\n",
       " 218    789600.0\n",
       " 96     449400.0\n",
       " 239    430500.0\n",
       " 40     732900.0\n",
       " 20     285600.0\n",
       " 123    363300.0\n",
       " 164    499800.0\n",
       " 313    525000.0\n",
       " 291    554400.0\n",
       " 459    350700.0\n",
       " 172    487200.0\n",
       " 383    117600.0\n",
       " 210    602700.0\n",
       " 190    699300.0\n",
       " 234    466200.0\n",
       " 158    510300.0\n",
       " 26     348600.0\n",
       " 198    474600.0\n",
       " 196    888300.0\n",
       " 16     485100.0\n",
       " 471    319200.0\n",
       " Name: MEDV, Length: 391, dtype: float64, 161    476700.0\n",
       " 30     266700.0\n",
       " 374    487200.0\n",
       " 473    170100.0\n",
       " 405    436800.0\n",
       " 125    449400.0\n",
       " 451    401100.0\n",
       " 427    226800.0\n",
       " 139    373800.0\n",
       " 484    470400.0\n",
       " 474    285600.0\n",
       " 226    609000.0\n",
       " 37     441000.0\n",
       " 401    184800.0\n",
       " 61     336000.0\n",
       " 70     508200.0\n",
       " 4      760200.0\n",
       " 251    709800.0\n",
       " 208    525000.0\n",
       " 166    365400.0\n",
       " 300    464100.0\n",
       " 91     462000.0\n",
       " 221    661500.0\n",
       " 222    510300.0\n",
       " 115    384300.0\n",
       " 249    756000.0\n",
       " 5      602700.0\n",
       " 21     411600.0\n",
       " 424    359100.0\n",
       " 485    432600.0\n",
       "          ...   \n",
       " 245    898800.0\n",
       " 394    361200.0\n",
       " 121    426300.0\n",
       " 429    312900.0\n",
       " 355    485100.0\n",
       " 211    451500.0\n",
       " 89     602700.0\n",
       " 238    510300.0\n",
       " 207    497700.0\n",
       " 162    525000.0\n",
       " 213    560700.0\n",
       " 248    924000.0\n",
       " 464    497700.0\n",
       " 124    394800.0\n",
       " 132    483000.0\n",
       " 366    258300.0\n",
       " 19     382200.0\n",
       " 206    590100.0\n",
       " 444    371700.0\n",
       " 341    390600.0\n",
       " 463    483000.0\n",
       " 126    329700.0\n",
       " 113    392700.0\n",
       " 399    157500.0\n",
       " 59     411600.0\n",
       " 357    289800.0\n",
       " 152    321300.0\n",
       " 92     480900.0\n",
       " 212    483000.0\n",
       " 371    214200.0\n",
       " Name: MEDV, Length: 98, dtype: float64]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_split(features, prices, train_size=0.80, test_size=0.20, random_state=424)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 2 - 训练及测试\n",
    "*将数据集按一定比例分为训练用的数据集和测试用的数据集对学习算法有什么好处？*\n",
    "\n",
    "*如果用模型已经见过的数据，例如部分训练集数据进行测试，又有什么坏处？*\n",
    "\n",
    "**提示：** 如果没有数据来对模型进行测试，会出现什么问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 2 - 回答:\n",
    "将数据集分为训练集和测试集的原因是防止过度拟合。如果全部用来做训练，建立的模型自然是最契合这些数据的，用其他的数据集效果可能不佳。同样的，入股用已见过的数据来测试，对于模型表现的评估一定是虚高的，因为模型是用训练数据集来建立的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第三步. 模型衡量标准\n",
    "在项目的第三步中，你需要了解必要的工具和技巧来让你的模型进行预测。用这些工具和技巧对每一个模型的表现做精确的衡量可以极大地增强你预测的信心。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习3：定义衡量标准\n",
    "如果不能对模型的训练和测试的表现进行量化地评估，我们就很难衡量模型的好坏。通常我们会定义一些衡量标准，这些标准可以通过对某些误差或者拟合程度的计算来得到。在这个项目中，你将通过运算[*决定系数*](http://stattrek.com/statistics/dictionary.aspx?definition=coefficient_of_determination) R<sup>2</sup> 来量化模型的表现。模型的决定系数是回归分析中十分常用的统计信息，经常被当作衡量模型预测能力好坏的标准。\n",
    "\n",
    "R<sup>2</sup>的数值范围从0至1，表示**目标变量**的预测值和实际值之间的相关程度平方的百分比。一个模型的R<sup>2</sup> 值为0还不如直接用**平均值**来预测效果好；而一个R<sup>2</sup> 值为1的模型则可以对目标变量进行完美的预测。从0至1之间的数值，则表示该模型中目标变量中有百分之多少能够用**特征**来解释。_模型也可能出现负值的R<sup>2</sup>，这种情况下模型所做预测有时会比直接计算目标变量的平均值差很多。_\n",
    "\n",
    "在下方代码的 `performance_metric` 函数中，你要实现：\n",
    "- 使用 `sklearn.metrics` 中的 [`r2_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) 来计算 `y_true` 和 `y_predict`的R<sup>2</sup>值，作为对其表现的评判。\n",
    "- 将他们的表现评分储存到`score`变量中。\n",
    "\n",
    "或 \n",
    "\n",
    "- (可选) 不使用任何外部库，参考[决定系数的定义](https://en.wikipedia.org/wiki/Coefficient_of_determination)进行计算，这也可以帮助你更好的理解决定系数在什么情况下等于0或等于1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\"计算并返回预测值相比于预测值的分数\"\"\"\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 3 可选\n",
    "\n",
    "# 不允许导入任何计算决定系数的库\n",
    "\n",
    "def performance_metric2(y_true, y_predict):\n",
    "    \"\"\"计算并返回预测值相比于预测值的分数\"\"\"\n",
    "    \n",
    "    score = None\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 3 - 拟合程度\n",
    "\n",
    "假设一个数据集有五个数据且一个模型做出下列目标变量的预测：\n",
    "\n",
    "| 真实数值 | 预测数值 |\n",
    "| :-------------: | :--------: |\n",
    "| 3.0 | 2.5 |\n",
    "| -0.5 | 0.0 |\n",
    "| 2.0 | 2.1 |\n",
    "| 7.0 | 7.8 |\n",
    "| 4.2 | 5.3 |\n",
    "*你觉得这个模型已成功地描述了目标变量的变化吗？如果成功，请解释为什么，如果没有，也请给出原因。*  \n",
    "\n",
    "**提示**：运行下方的代码，使用`performance_metric`函数来计算模型的决定系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算这个模型的预测结果的决定系数\n",
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print \"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 3 - 回答:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第四步. 分析模型的表现\n",
    "在项目的第四步，我们来看一下不同参数下，模型在训练集和验证集上的表现。这里，我们专注于一个特定的算法（带剪枝的决策树，但这并不是这个项目的重点），和这个算法的一个参数 `'max_depth'`。用全部训练集训练，选择不同`'max_depth'` 参数，观察这一参数的变化如何影响模型的表现。画出模型的表现来对于分析过程十分有益，这可以让我们看到一些单看结果看不到的行为。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习曲线\n",
    "下方区域内的代码会输出四幅图像，它们是一个决策树模型在不同最大深度下的表现。每一条曲线都直观得显示了随着训练数据量的增加，模型学习曲线的在训练集评分和验证集评分的变化，评分使用决定系数R<sup>2</sup>。曲线的阴影区域代表的是该曲线的不确定性（用标准差衡量）。\n",
    "\n",
    "运行下方区域中的代码，并利用输出的图形回答下面的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 根据不同的训练集大小，和最大深度，生成学习曲线\n",
    "vs.ModelLearning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 4 - 学习曲线\n",
    "*选择上述图像中的其中一个，并给出其最大深度。随着训练数据量的增加，训练集曲线的评分有怎样的变化？验证集曲线呢？如果有更多的训练数据，是否能有效提升模型的表现呢？*\n",
    "\n",
    "**提示：**学习曲线的评分是否最终会收敛到特定的值？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 4 - 回答:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复杂度曲线\n",
    "下列代码内的区域会输出一幅图像，它展示了一个已经经过训练和验证的决策树模型在不同最大深度条件下的表现。这个图形将包含两条曲线，一个是训练集的变化，一个是验证集的变化。跟**学习曲线**相似，阴影区域代表该曲线的不确定性，模型训练和测试部分的评分都用的 `performance_metric` 函数。\n",
    "\n",
    "运行下方区域中的代码，并利用输出的图形并回答下面的两个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 根据不同的最大深度参数，生成复杂度曲线\n",
    "vs.ModelComplexity(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 5 - 偏差（bias）与方差（variance）之间的权衡取舍\n",
    "*当模型以最大深度 1训练时，模型的预测是出现很大的偏差还是出现了很大的方差？当模型以最大深度10训练时，情形又如何呢？图形中的哪些特征能够支持你的结论？*\n",
    "  \n",
    "**提示：** 你如何得知模型是否出现了偏差很大或者方差很大的问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 5 - 回答:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 6- 最优模型的猜测\n",
    "*结合问题 5 中的图，你认为最大深度是多少的模型能够最好地对未见过的数据进行预测？你得出这个答案的依据是什么？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 6 - 回答:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第五步. 选择最优参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 7- 网格搜索（Grid Search）\n",
    "*什么是网格搜索法？如何用它来优化模型？*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 7 - 回答:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 8 - 交叉验证\n",
    "- 什么是K折交叉验证法（k-fold cross-validation）？\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)是如何结合交叉验证来完成对最佳参数组合的选择的？\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)中的`'cv_results_'`属性能告诉我们什么？\n",
    "- 网格搜索时如果不使用交叉验证会有什么问题？交叉验证又是如何解决这个问题的？\n",
    "\n",
    "**提示：** 在下面 fit_model函数最后加入 `print pd.DataFrame(grid.cv_results_)` 可以帮你查看更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 8 - 回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习 4：训练最优模型\n",
    "在这个练习中，你将需要将所学到的内容整合，使用**决策树算法**训练一个模型。为了得出的是一个最优模型，你需要使用网格搜索法训练模型，以找到最佳的 `'max_depth'` 参数。你可以把`'max_depth'` 参数理解为决策树算法在做出预测前，允许其对数据提出问题的数量。决策树是**监督学习算法**中的一种。\n",
    "\n",
    "在下方 `fit_model` 函数中，你需要做的是：\n",
    "1. **定义 `'cross_validator'` 变量**: 使用 `sklearn.model_selection` 中的 [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) 创建一个交叉验证生成器对象;\n",
    "2. **定义 `'regressor'` 变量**: 使用  `sklearn.tree` 中的 [`DecisionTreeRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) 创建一个决策树的回归函数;\n",
    "3. **定义 `'params'` 变量**: 为 `'max_depth'` 参数创造一个字典，它的值是从1至10的数组;\n",
    "4. **定义 `'scoring_fnc'` 变量**: 使用 `sklearn.metrics` 中的 [`make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html)  创建一个评分函数；\n",
    " 将 `‘performance_metric’` 作为参数传至这个函数中；\n",
    "5. **定义 `'grid'` 变量**: 使用 `sklearn.model_selection` 中的 [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 创建一个网格搜索对象；将变量`'regressor'`, `'params'`, `'scoring_fnc'`和 `'cross_validator'` 作为参数传至这个对象构造函数中；\n",
    "  \n",
    "如果你对python函数的默认参数定义和传递不熟悉，可以参考这个MIT课程的[视频](http://cn-static.udacity.com/mlnd/videos/MIT600XXT114-V004200_DTH.mp4)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 4\n",
    "\n",
    "#提示: 导入 'KFold' 'DecisionTreeRegressor' 'make_scorer' 'GridSearchCV' \n",
    "\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" 基于输入数据 [X,y]，利于网格搜索找到最优的决策树模型\"\"\"\n",
    "    \n",
    "    cross_validator = None\n",
    "    \n",
    "    regressor = None\n",
    "\n",
    "    params = None\n",
    "\n",
    "    scoring_fnc = None\n",
    "\n",
    "    grid = None\n",
    "\n",
    "    # 基于输入数据 [X,y]，进行网格搜索\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # 返回网格搜索后的最优模型\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习 4：训练最优模型 （可选）\n",
    "在这个练习中，你将需要将所学到的内容整合，使用**决策树算法**训练一个模型。为了得出的是一个最优模型，你需要使用网格搜索法训练模型，以找到最佳的 `'max_depth'` 参数。你可以把`'max_depth'` 参数理解为决策树算法在做出预测前，允许其对数据提出问题的数量。决策树是**监督学习算法**中的一种。\n",
    "\n",
    "在下方 `fit_model` 函数中，你需要做的是：\n",
    "\n",
    "- 遍历参数`‘max_depth’`的可选值 1～10，构造对应模型\n",
    "- 计算当前模型的交叉验证分数\n",
    "- 返回最优交叉验证分数对应的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 4 可选\n",
    "\n",
    "'''\n",
    "不允许使用 DecisionTreeRegressor 以外的任何 sklearn 库\n",
    "\n",
    "提示: 你可能需要实现下面的 cross_val_score 函数\n",
    "\n",
    "def cross_val_score(estimator, X, y, scoring = performance_metric, cv=3):\n",
    "    \"\"\" 返回每组交叉验证的模型分数的数组 \"\"\"\n",
    "    scores = [0,0,0]\n",
    "    return scores\n",
    "'''\n",
    "\n",
    "def fit_model2(X, y):\n",
    "    \"\"\" 基于输入数据 [X,y]，利于网格搜索找到最优的决策树模型\"\"\"\n",
    "    \n",
    "    #最优交叉验证分数对应的最优模型\n",
    "    best_estimator = None\n",
    "    \n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 9 - 最优模型\n",
    "*最优模型的最大深度（maximum depth）是多少？此答案与你在**问题 6**所做的猜测是否相同？*\n",
    "\n",
    "运行下方区域内的代码，将决策树回归函数代入训练数据的集合，以得到最优化的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 基于训练数据，获得最优模型\n",
    "optimal_reg = fit_model(X_train, y_train)\n",
    "\n",
    "# 输出最优模型的 'max_depth' 参数\n",
    "print \"Parameter 'max_depth' is {} for the optimal model.\".format(optimal_reg.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 9 - 回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六步. 做出预测\n",
    "当我们用数据训练出一个模型，它现在就可用于对新的数据进行预测。在决策树回归函数中，模型已经学会对新输入的数据*提问*，并返回对**目标变量**的预测值。你可以用这个预测来获取数据未知目标变量的信息，这些数据必须是不包含在训练数据之内的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 10 - 预测销售价格\n",
    "想像你是一个在波士顿地区的房屋经纪人，并期待使用此模型以帮助你的客户评估他们想出售的房屋。你已经从你的三个客户收集到以下的资讯:\n",
    "\n",
    "| 特征 | 客戶 1 | 客戶 2 | 客戶 3 |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| 房屋内房间总数 | 5 间房间 | 4 间房间 | 8 间房间 |\n",
    "| 社区贫困指数（％被认为是贫困阶层） | 17% | 32% | 3% |\n",
    "| 邻近学校的学生-老师比例 | 15：1 | 22：1 | 12：1 |\n",
    "\n",
    "*你会建议每位客户的房屋销售的价格为多少？从房屋特征的数值判断，这样的价格合理吗？为什么？* \n",
    "\n",
    "**提示：**用你在**分析数据**部分计算出来的统计信息来帮助你证明你的答案。\n",
    "\n",
    "运行下列的代码区域，使用你优化的模型来为每位客户的房屋价值做出预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成三个客户的数据\n",
    "client_data = [[5, 17, 15], # 客户 1\n",
    "               [4, 32, 22], # 客户 2\n",
    "               [8, 3, 12]]  # 客户 3\n",
    "\n",
    "# 进行预测\n",
    "predicted_price = optimal_reg.predict(client_data)\n",
    "for i, price in enumerate(predicted_price):\n",
    "    print \"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 10 - 回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习 5\n",
    "你刚刚预测了三个客户的房子的售价。在这个练习中，你将用你的最优模型在整个测试数据上进行预测, 并计算相对于目标变量的决定系数 R<sup>2</sup>的值**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO 5\n",
    "\n",
    "# 提示：你可能需要用到 X_test, y_test, optimal_reg, performance_metric\n",
    "# 提示：你可能需要参考问题10的代码进行预测\n",
    "# 提示：你可能需要参考问题3的代码来计算R^2的值\n",
    "\n",
    "r2 = 1\n",
    "\n",
    "print \"Optimal model has R^2 score {:,.2f} on test data\".format(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题11 - 分析决定系数\n",
    "\n",
    "你刚刚计算了最优模型在测试集上的决定系数，你会如何评价这个结果？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题11 - 回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型健壮性\n",
    "\n",
    "一个最优的模型不一定是一个健壮模型。有的时候模型会过于复杂或者过于简单，以致于难以泛化新增添的数据；有的时候模型采用的学习算法并不适用于特定的数据结构；有的时候样本本身可能有太多噪点或样本过少，使得模型无法准确地预测目标变量。这些情况下我们会说模型是欠拟合的。\n",
    "\n",
    "### 问题 12 - 模型健壮性\n",
    "\n",
    "模型是否足够健壮来保证预测的一致性？\n",
    "\n",
    "**提示**: 执行下方区域中的代码，采用不同的训练和测试集执行 `fit_model` 函数10次。注意观察对一个特定的客户来说，预测是如何随训练数据的变化而变化的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 请先注释掉 fit_model 函数里的所有 print 语句\n",
    "vs.PredictTrials(features, prices, fit_model, client_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 12 - 回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 13 - 实用性探讨\n",
    "*简单地讨论一下你建构的模型能否在现实世界中使用？* \n",
    "\n",
    "提示：回答以下几个问题，并给出相应结论的理由：\n",
    "- *1978年所采集的数据，在已考虑通货膨胀的前提下，在今天是否仍然适用？*\n",
    "- *数据中呈现的特征是否足够描述一个房屋？*\n",
    "- *在波士顿这样的大都市采集的数据，能否应用在其它乡镇地区？*\n",
    "- *你觉得仅仅凭房屋所在社区的环境来判断房屋价值合理吗？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 13 - 回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可选问题 - 预测北京房价\n",
    "\n",
    "（本题结果不影响项目是否通过）通过上面的实践，相信你对机器学习的一些常用概念有了很好的领悟和掌握。但利用70年代的波士顿房价数据进行建模的确对我们来说意义不是太大。现在你可以把你上面所学应用到北京房价数据集中 `bj_housing.csv`。\n",
    "\n",
    "免责声明：考虑到北京房价受到宏观经济、政策调整等众多因素的直接影响，预测结果仅供参考。\n",
    "\n",
    "这个数据集的特征有：\n",
    "- Area：房屋面积，平方米\n",
    "- Room：房间数，间\n",
    "- Living: 厅数，间\n",
    "- School: 是否为学区房，0或1\n",
    "- Year: 房屋建造时间，年\n",
    "- Floor: 房屋所处楼层，层\n",
    "\n",
    "目标变量：\n",
    "- Value: 房屋人民币售价，万\n",
    "\n",
    "你可以参考上面学到的内容，拿这个数据集来练习数据分割与重排、定义衡量标准、训练模型、评价模型表现、使用网格搜索配合交叉验证对参数进行调优并选出最佳参数，比较两者的差别，最终得出最佳模型对验证集的预测分数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 6\n",
    "\n",
    "# 你的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题14 - 北京房价预测\n",
    "你成功的用新的数据集构建了模型了吗？他能对测试数据进行验证吗？它的表现是否符合你的预期？交叉验证是否有助于提升你模型的表现？\n",
    "\n",
    "**提示：**如果你是从零开始构建机器学习的代码会让你一时觉得无从下手。这时不要着急，你要做的只是查看之前写的代码，把每一行都看明白，然后逐步构建你的模型。当中遇到什么问题也可以在我们论坛寻找答案。也许你会发现你所构建的模型的表现并没有达到你的预期，这说明机器学习并非是一项简单的任务，构建一个表现良好的模型需要长时间的研究和测试。这也是我们接下来的课程中会逐渐学到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题14 - 回答"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
